{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Guide to Scikit-Learn — Building a Machine Learning Model in Python\n",
    "\n",
    "Source: https://towardsdatascience.com/a-beginners-guide-to-text-classification-with-scikit-learn-632357e16f3a\n",
    "\n",
    "Problem formulation: Our goal is to find which machine learning model is best suited to predict sentiment (output) given a movie review (input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the data\n",
    "# reading the dataset\n",
    "\n",
    "import pandas as pd\n",
    "df_review = pd.read_csv('IMDB Dataset.csv')\n",
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains 50000 rows; however, to train our model faster in the following steps, \n",
    "# we’re going to take a smaller sample of 10000 rows. \n",
    "# This small sample will contain 9000 positive and 1000 negative reviews to make the data imbalanced\n",
    "\n",
    "df_positive = df_review[df_review['sentiment']=='positive'][:9000]\n",
    "df_negative = df_review[df_review['sentiment']=='negative'][:1000]\n",
    "df_review_imb = pd.concat([df_positive, df_negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  review\n",
       "0  negative    1000\n",
       "1  positive    9000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = (df_review_imb\n",
    "      .groupby(['sentiment'],as_index=False)\n",
    "      .count()\n",
    "      )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df['sentiment'], df['review'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are more positive than negative reviews in <code>df_review_imb</code> so we have imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Knute Rockne led an extraordinary life and his...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>At the height of the 'Celebrity Big Brother' r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>This is another of Robert Altman's underrated ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>This movie won a special award at Cannes for i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>You'd be forgiven to think a Finnish director ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     Basically there's a family where a little boy ...  negative\n",
       "1     This show was an amazing, fresh & innovative i...  negative\n",
       "2     Encouraged by the positive comments about this...  negative\n",
       "3     Phil the Alien is one of those quirky films wh...  negative\n",
       "4     I saw this movie when I was about 12 when it c...  negative\n",
       "...                                                 ...       ...\n",
       "1995  Knute Rockne led an extraordinary life and his...  positive\n",
       "1996  At the height of the 'Celebrity Big Brother' r...  positive\n",
       "1997  This is another of Robert Altman's underrated ...  positive\n",
       "1998  This movie won a special award at Cannes for i...  positive\n",
       "1999  You'd be forgiven to think a Finnish director ...  positive\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use the imblearn library and RandomUnderSampler function to balance the data\n",
    "\n",
    "from imblearn.under_sampling import  RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "df_review_bal, df_review_bal['sentiment']=rus.fit_resample(df_review_imb[['review']],\n",
    "                                                           df_review_imb['sentiment'])\n",
    "df_review_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    9000\n",
      "negative    1000\n",
      "dtype: int64\n",
      "sentiment\n",
      "positive    1000\n",
      "negative    1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# After this, x and y are balanced and we’ll store it in a new dataset named df_review_bal\n",
    "\n",
    "print(df_review_imb.value_counts('sentiment'))\n",
    "print(df_review_bal.value_counts('sentiment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use sklearn’s <code>train_test_split</code> to do the job. In this case, we set 33% to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_review_bal, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set the independent and dependent variables within our train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train['review'], train['sentiment']\n",
    "test_x, test_y = test['review'], test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers and learning algorithms expect numerical feature vectors rather than raw text documents. This is why we need to turn our movie review text into numerical vectors. There are many text representation techniques such as one-hot encoding, bag of words, and wor2vec.\n",
    "\n",
    "For this simple, we’ll use bag of words (BOW) since we care about the frequency of the words in text reviews; however, the order of words is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning our text data into numerical vectors\n",
    "\n",
    "In our original dataset, we want to identify unique/representative words for positive reviews and negative reviews, so we’ll choose the TF-IDF. To turn text data into numerical vectors with TF-IDF, we write the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1340x20625 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 118834 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "train_x_vector = tfidf.fit_transform(train_x)\n",
    "train_x_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>01pm</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zues</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>æon</th>\n",
       "      <th>élan</th>\n",
       "      <th>émigré</th>\n",
       "      <th>ísnt</th>\n",
       "      <th>ïn</th>\n",
       "      <th>ünfaithful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340 rows × 20625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  007  01pm   02   04   08        10  100  1000  ...  zooming  \\\n",
       "81    0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "915   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1018  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "380   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.042791  0.0   0.0  ...      0.0   \n",
       "1029  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "...   ...  ...  ...   ...  ...  ...  ...       ...  ...   ...  ...      ...   \n",
       "1130  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1294  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "860   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1459  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "1126  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.000000  0.0   0.0  ...      0.0   \n",
       "\n",
       "      zooms  zues  zzzzzzzzzzzzzzzzzz  æon  élan  émigré  ísnt   ïn  \\\n",
       "81      0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "915     0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1018    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "380     0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1029    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "...     ...   ...                 ...  ...   ...     ...   ...  ...   \n",
       "1130    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1294    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "860     0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1459    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "1126    0.0   0.0                 0.0  0.0   0.0     0.0   0.0  0.0   \n",
       "\n",
       "      ünfaithful  \n",
       "81           0.0  \n",
       "915          0.0  \n",
       "1018         0.0  \n",
       "380          0.0  \n",
       "1029         0.0  \n",
       "...          ...  \n",
       "1130         0.0  \n",
       "1294         0.0  \n",
       "860          0.0  \n",
       "1459         0.0  \n",
       "1126         0.0  \n",
       "\n",
       "[1340 rows x 20625 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(train_x_vector,\n",
    "                                  index=train_x.index,\n",
    "                                  columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test_x_vector, so we can test the accuracy of the model later\n",
    "\n",
    "test_x_vector = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)\n",
    "To fit an SVM model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting <code>svc</code> we can predict whether a review is positive or negative with the <code>.predict()</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['positive']\n",
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "print(svc.predict(tfidf.transform(['A good movie'])))\n",
    "print(svc.predict(tfidf.transform(['An excellent movie'])))\n",
    "print(svc.predict(tfidf.transform(['I did not like this movie at all'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "To fit a decision tree model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "To fit a Naive Bayes model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x_vector.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "To fit a Logistic Regression model, we need to introduce the input (text reviews as numerical vectors) and output (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "In this section, we’ll see traditional metrics used to evaluate our models.\n",
    "Mean Accuracy\n",
    "\n",
    "To obtain the mean accuracy of each model, just use the <code>.score</code> method with the test samples and true labels as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8409090909090909\n",
      "0.6651515151515152\n",
      "0.6348484848484849\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# svc.score('Test samples', 'True labels')\n",
    "\n",
    "print(svc.score(test_x_vector, test_y))\n",
    "print(dec_tree.score(test_x_vector, test_y))\n",
    "print(gnb.score(test_x_vector.toarray(), test_y))\n",
    "print(log_reg.score(test_x_vector, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "F1 Score is the weighted average of Precision and Recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84671533, 0.83464567])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y, svc.predict(test_x_vector),\n",
    "         labels=['positive', 'negative'],\n",
    "         average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "We can also build a text report showing the main classification metrics that include those calculated before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.87      0.85       335\n",
      "    negative       0.85      0.82      0.83       325\n",
      "\n",
      "    accuracy                           0.84       660\n",
      "   macro avg       0.84      0.84      0.84       660\n",
      "weighted avg       0.84      0.84      0.84       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, \n",
    "                            svc.predict(test_x_vector),\n",
    "                            labels=['positive', 'negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "A confusion matrix) is a table that allows visualization of the performance of an algorithm. This table typically has two rows and two columns that report the number of false positives, false negatives, true positives, and true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[290,  45],\n",
       "       [ 60, 265]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(test_y, \n",
    "                            svc.predict(test_x_vector), \n",
    "                            labels=['positive', 'negative'])\n",
    "\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Model\n",
    "Finally, it’s time to maximize our model’s performance.\n",
    "\n",
    "#### GridSearchCV\n",
    "This is technique consists of an exhaustive search on specified parameters in order to obtain the optimum values of hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#set the parameters\n",
    "parameters = {'C': [1,4,8,16,32] ,'kernel':['linear', 'rbf']}\n",
    "svc = SVC()\n",
    "svc_grid = GridSearchCV(svc,parameters, cv=5)\n",
    "\n",
    "svc_grid.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(svc_grid.best_params_)\n",
    "print(svc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
